Boyer-Moore算法只适合 alternation 一定的相等字符
比如  this|that  or  th(is|at)
但是如果 this|those就不太适应了  还有就是字符串越长效率越高o

这种高效的识别字符串Moore算法  必须用在固定位置的相同长度或者确定长度
比如  \b(perl|ruby)\.regex\.info
这样我们想要寻找的字符串是必须包含.regex.info 然后向前4个位置开始使用正则表达式
而如果是\b(perl|python)\.regex\.info或者\b(\w+)\.regex\.info 由于在
确定必须含有.regex.info 之前是不缺定的字符串  所以无法运用Boyer_moore算法
进行高效查找！！！
所以一定要提醒自己在确定的字符串前的固定长度

还有就是  \d{3} 替换\d\d\d  但是此法对字符串没有效果  只对数字有效果 比如==== 比={4} 快上很多 应该是boyer-moore算法的原因把!
[a-z]  替换a|b|c|...|z
显示表达出字符串
使用  ^ $ \b \A \G等猫点

避免徒劳的回溯
^\w+:  改成 or ^\w++:  ^(?>\w+):  
(?>^\w+):  按理说也是可以的   这种原子可以避免\w+碰到非：的徒劳追溯！！！

th(?=is|at)  th(?=at|is) th(?:is|at) #原子组合是在抛弃了那些匹配状态的同时使状态向前推进  而环视并没有 他只是在自己的小世界里把bump向前推进了！！！这是两者最大的不同点  其他基本上相似或者叫做一样！! 比如最经典
(?>dfff) ==(?=dfff)\dfff 但是还有一点就是如果有()在环视中照样会影响$1的 同时\dfff也会影响速度！ 所以各有利弊  

独立文本是非常重要的
比如 不要用this:|that:替换 (?:this|that):
因为前者违背了把文本孤立出来 把：惨入其中

消除循环 其实是在.的基础上提起的不想让点号匹配太多
比如 [^\\*] 不是\ and *的所有字符
\\. 匹配字符串离得\n \" \* \t \r 之类的！
我们假设把[^\\*] 当作normal部分
        把\\. 当作special部分   如果他们能够重合在同一位置开始那就不好！
    也就是special & normal 必须等于0  无交集的起始点才行！ 必须满足这个条件才能避免无休止的重复
    把你选好的任意的special normal都运用到这个方程进行求解
    normal * (special normal*)*进行求解
    这边就要求normal必须至少是一个以上字符  而 special 必须是固定文本！special部分必须固化，如果不固化的话 会出现既可以匹配部分文本又可以匹配全部文本的现象！必须消除这种不确定性的可能 减少循环！！！

总结：消除循环的常用解法：
  opening normal* (special normal*)* closing

  "[^\\"](\\.[^\\"]*)*"  special = \\.   normal = [^\\"] 
  首先不相交  其次special固化  再次normal至少一个字符
  normal一般是字符组  而special一般是\\.之类的
 special部分被作为检查点 所以必须是固化 而不能虚无不定

 效率更高的一种组合
 special* (normal special*)*
 也就是 假设special = .  normal =\{[^]*\}
 那么整体 ： .*(\{[^]}*\}.*)*

 normal部分匹配常见的文本
 以上原理一般用在出现*  +的情况下

 [a-z]+(\.[a-z]+)*
上式显然是跟"[^\\"]+(\\.[^\\"]+)*" 具有极大的相似性
只不过在上式的url域名处理时normal必须不为空因为URl中的两点之间
必须有字母  而“”这个正则表达式 可以把+ 改为* 虽然我们建议normal 
至少一个以上  这边也说名normal也是可以是[a-z]非[^]这种形式的

再接着对这个公式进行优化
就是用固化分组 或原子组合了
(....| ...)*+  (?>(...|...)*)而不是(?>[^\\"]+|\\.)*这样仅仅是优化了
仅仅消除多选结构保留的状态 而*是独立于固化分组,并不会应包跳过本轮的
状态回溯 也就是这个固化分组对这些状态并没有消除
